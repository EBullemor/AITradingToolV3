#!/usr/bin/env python3
"""
Backtest Pipeline V1

Production-ready backtest engine that validates strategies against historical data.
Integrates the Cross-Asset Risk Overlay (Pod 4) for signal gating.

Strategies tested:
  - FX Carry + Momentum (Pod 1): EURUSD, USDJPY, GBPUSD, AUDUSD
  - Commodities TS + Momentum (Pod 3): WTI, Gold, Copper

Data sources:
  - fx_spots_clean.csv
  - rates_clean.csv
  - macros_clean.csv
  - commodities_clean.csv

Usage:
    python -m pipelines.backtest
    python -m pipelines.backtest --start 2022-01-01 --end 2025-12-31
    python -m pipelines.backtest --no-risk-overlay
    python -m pipelines.backtest --output reports/backtest_v1.xlsx
"""

import argparse
import json
import sys
import warnings
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from loguru import logger

warnings.filterwarnings("ignore")

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))


# =============================================================================
# Configuration
# =============================================================================

@dataclass
class BacktestConfig:
    """Backtest configuration."""
    start_date: str = "2021-01-01"
    end_date: str = "2026-02-01"
    initial_capital: float = 100_000.0
    # Position sizing
    risk_per_trade_pct: float = 0.01       # 1% risk per trade
    max_position_pct: float = 0.10         # 10% max per position
    max_gross_exposure: float = 1.0        # 100% max gross
    max_concurrent: int = 8               # Max open positions
    # Signal timing
    signal_rebalance_days: int = 5        # Generate signals every N days
    max_holding_days: int = 30            # Force close after N days
    # Transaction costs (round-trip)
    fx_spread_bps: float = 1.0
    fx_slippage_bps: float = 0.5
    cmdty_spread_bps: float = 3.0
    cmdty_slippage_bps: float = 2.0
    # Risk overlay
    use_risk_overlay: bool = True
    vix_kill_threshold: float = 30.0
    # Paths
    data_dir: Path = Path("data/clean")
    output_dir: Path = Path("reports")


# =============================================================================
# Data Structures
# =============================================================================

@dataclass
class TradeSignal:
    """Signal generated by a strategy."""
    date: datetime
    instrument: str
    direction: str       # LONG or SHORT
    strength: float      # 0.0 to 1.0
    entry_price: float
    stop_loss: float
    take_profit: float
    strategy: str
    regime: str
    rationale: str
    atr: float = 0.0
    risk_overlay_scalar: float = 1.0


@dataclass
class Trade:
    """Executed trade with full lifecycle."""
    signal: TradeSignal
    entry_date: datetime
    entry_price: float
    position_size: float     # Notional value
    risk_amount: float
    exit_date: Optional[datetime] = None
    exit_price: Optional[float] = None
    exit_reason: Optional[str] = None
    gross_pnl: float = 0.0
    net_pnl: float = 0.0
    cost: float = 0.0
    pnl_pct: float = 0.0
    holding_days: int = 0

    @property
    def is_open(self): return self.exit_date is None
    @property
    def is_winner(self): return self.net_pnl > 0


# =============================================================================
# Data Loading
# =============================================================================

def find_data_dir() -> Path:
    """Find CSV data directory (checks multiple locations)."""
    candidates = [
        Path("data/clean"),
        Path("data"),
        Path("."),
        Path(__file__).parent.parent / "data" / "clean",
        Path(__file__).parent.parent / "data",
        Path(__file__).parent.parent,
    ]
    for d in candidates:
        if (d / "fx_spots_clean.csv").exists():
            return d
    raise FileNotFoundError("Cannot find CSV data files. Expected: fx_spots_clean.csv, etc.")


def load_all_data(data_dir: Path) -> Dict[str, pd.DataFrame]:
    """Load all CSV data files."""
    logger.info(f"Loading data from {data_dir}")
    data = {}
    files = {
        "fx": "fx_spots_clean.csv",
        "rates": "rates_clean.csv",
        "macros": "macros_clean.csv",
        "commodities": "commodities_clean.csv",
    }
    for key, filename in files.items():
        path = data_dir / filename
        if not path.exists():
            logger.warning(f"Missing: {path}")
            continue
        df = pd.read_csv(path, parse_dates=["date"]).set_index("date").sort_index().ffill()
        data[key] = df
        logger.info(f"  {key}: {df.index[0].date()} → {df.index[-1].date()} ({len(df)} rows)")
    return data


# =============================================================================
# Feature Engineering
# =============================================================================

def _log_returns(p, n=1):
    return np.log(p / p.shift(n))

def _momentum_zscore(p, periods=(21, 63, 126), weights=(0.5, 0.3, 0.2)):
    scores = []
    for per, w in zip(periods, weights):
        r = _log_returns(p, per)
        z = (r - r.rolling(252).mean()) / r.rolling(252).std()
        scores.append(z * w)
    return sum(scores)

def _trend_strength(p, short=20, long=60):
    return (p.rolling(short).mean() - p.rolling(long).mean()) / p.rolling(long).mean()

def _realized_vol(p, w=20):
    return _log_returns(p).rolling(w).std() * np.sqrt(252)

def _atr(p, n=14):
    return p.pct_change().abs().rolling(n).mean() * p * 1.5

def _rsi(p, n=14):
    d = p.diff()
    g = d.where(d > 0, 0).rolling(n).mean()
    l = (-d.where(d < 0, 0)).rolling(n).mean()
    rs = g / l.replace(0, np.nan)
    return 100 - (100 / (1 + rs))

def _carry_score(carry, vol):
    return carry / vol.clip(lower=0.01)

def _roll_yield(front, back):
    return ((front - back) / back) * (365 / 90) * 100

def _ts_slope(front, back):
    return (front - back) / back


def compute_all_features(data: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
    """Compute features for all instruments."""
    logger.info("Computing features...")
    features = {}
    fx = data.get("fx", pd.DataFrame())
    rates = data.get("rates", pd.DataFrame())
    macros = data.get("macros", pd.DataFrame())
    commodities = data.get("commodities", pd.DataFrame())

    # --- FX Pairs ---
    fx_rate_map = {
        "USDJPY": ("USD_12M_RATE", "JPY_12M_RATE"),
        "GBPUSD": ("GBP_12M_RATE", "USD_12M_RATE"),
        "AUDUSD": ("AUD_12M_RATE", "USD_12M_RATE"),
    }

    for pair in ["EURUSD", "USDJPY", "GBPUSD", "AUDUSD"]:
        if pair not in fx.columns:
            continue
        p = fx[pair].dropna()
        if len(p) < 300:
            continue

        f = pd.DataFrame(index=p.index)
        f["PX_LAST"] = p
        f["returns_1d"] = p.pct_change()
        f["momentum_score"] = _momentum_zscore(p)
        f["fx_momentum"] = _momentum_zscore(p, (20, 60, 120))
        f["trend_strength"] = _trend_strength(p)
        f["realized_vol_20d"] = _realized_vol(p, 20)
        f["atr_14"] = _atr(p)
        f["rsi_14"] = _rsi(p)

        rate_cols = fx_rate_map.get(pair)
        if rate_cols:
            br = rates[rate_cols[0]].reindex(p.index).ffill() if rate_cols[0] in rates.columns else None
            fr = rates[rate_cols[1]].reindex(p.index).ffill() if rate_cols[1] in rates.columns else None
            if br is not None and fr is not None:
                carry = br - fr
                f["carry"] = carry
                f["carry_score"] = _carry_score(carry, f["realized_vol_20d"])

        for col in ["VIX", "DXY", "SPX", "US_10Y_YIELD"]:
            if col in macros.columns:
                f[col.lower()] = macros[col].reindex(p.index).ffill()

        features[pair] = f
        logger.info(f"  {pair}: {len(f)} rows, {len(f.columns)} features")

    # --- Commodities ---
    cmdty_map = {
        "WTI": ("WTI_FRONT", "WTI_4TH"),
        "GOLD": ("GOLD_FRONT", None),
        "COPPER": ("COPPER_FRONT", None),
    }

    for name, (front_col, back_col) in cmdty_map.items():
        if front_col not in commodities.columns:
            continue
        p = commodities[front_col].dropna()
        if len(p) < 300:
            continue

        f = pd.DataFrame(index=p.index)
        f["PX_LAST"] = p
        f["returns_1d"] = p.pct_change()
        f["momentum_score"] = _momentum_zscore(p)
        f["trend_strength"] = _trend_strength(p)
        f["realized_vol_20d"] = _realized_vol(p, 20)
        f["atr_14"] = _atr(p)
        f["rsi_14"] = _rsi(p)

        if back_col and back_col in commodities.columns:
            bp = commodities[back_col].reindex(p.index).ffill()
            f["roll_yield"] = _roll_yield(p, bp)
            f["ts_slope"] = _ts_slope(p, bp)

        for col in ["VIX", "DXY", "SPX", "US_10Y_YIELD"]:
            if col in macros.columns:
                f[col.lower()] = macros[col].reindex(p.index).ffill()

        features[name] = f
        logger.info(f"  {name}: {len(f)} rows, {len(f.columns)} features")

    return features


# =============================================================================
# Signal Generation
# =============================================================================

def _get_regime(vix_val):
    if pd.isna(vix_val):
        return "NORMAL"
    if vix_val < 18:
        return "LOW_VOL"
    if vix_val > 25:
        return "HIGH_VOL"
    return "NORMAL"


def generate_fx_signal(inst: str, feat: pd.DataFrame, date) -> Optional[TradeSignal]:
    """Generate FX Carry+Momentum signal for a single pair on a given date."""
    mask = feat.index <= date
    f = feat[mask]
    if len(f) < 252:
        return None

    latest = f.iloc[-1]
    regime = _get_regime(latest.get("vix", 20))

    mom = latest.get("momentum_score", 0)
    fx_mom = latest.get("fx_momentum", mom)
    trend = latest.get("trend_strength", 0)
    carry = latest.get("carry_score", 0)

    if pd.isna(mom) or pd.isna(trend):
        return None

    direction = None
    strength = 0.0
    parts = []

    if regime == "LOW_VOL":
        if not pd.isna(carry) and abs(carry) > 0.5:
            if carry > 0.5 and mom > 0:
                direction, strength = "LONG", min(carry / 2.0, 1.0) * 0.8
                parts.append(f"Carry={carry:.2f}")
            elif carry < -0.5 and mom < 0:
                direction, strength = "SHORT", min(abs(carry) / 2.0, 1.0) * 0.8
                parts.append(f"Carry={carry:.2f}")
        if direction is None and abs(fx_mom) > 1.0 and abs(trend) > 0.005:
            if fx_mom > 1.0 and trend > 0:
                direction, strength = "LONG", min(fx_mom / 3.0, 1.0)
            elif fx_mom < -1.0 and trend < 0:
                direction, strength = "SHORT", min(abs(fx_mom) / 3.0, 1.0)
            if direction:
                parts.append(f"Mom={fx_mom:.2f}")
    elif regime == "HIGH_VOL":
        if abs(fx_mom) > 1.5 and abs(trend) > 0.01:
            if fx_mom > 1.5 and trend > 0:
                direction, strength = "LONG", min(fx_mom / 3.0, 1.0) * 0.7
            elif fx_mom < -1.5 and trend < 0:
                direction, strength = "SHORT", min(abs(fx_mom) / 3.0, 1.0) * 0.7
            if direction:
                parts.append(f"HiVol Mom={fx_mom:.2f}")
    else:  # NORMAL
        c_dir = ("LONG" if carry > 0 else "SHORT") if (not pd.isna(carry) and abs(carry) > 0.5) else None
        m_dir = None
        if abs(fx_mom) > 1.0 and abs(trend) > 0.005:
            m_dir = "LONG" if (fx_mom > 0 and trend > 0) else ("SHORT" if (fx_mom < 0 and trend < 0) else None)

        if c_dir and m_dir and c_dir == m_dir:
            direction = c_dir
            strength = min((abs(carry) / 2 + abs(fx_mom) / 3) / 2, 1.0) * 1.1
            parts.append(f"Aligned C={carry:.2f} M={fx_mom:.2f}")
        elif c_dir and m_dir:
            direction = c_dir if abs(carry) > abs(fx_mom) / 2 else m_dir
            strength = 0.4
            parts.append("Conflicting, reduced")
        elif c_dir:
            direction, strength = c_dir, min(abs(carry) / 2, 1.0) * 0.7
            parts.append(f"Carry={carry:.2f}")
        elif m_dir:
            direction, strength = m_dir, min(abs(fx_mom) / 3, 1.0) * 0.7
            parts.append(f"Mom={fx_mom:.2f}")

    if direction is None or strength < 0.15:
        return None
    strength = min(strength, 1.0)

    entry = latest["PX_LAST"]
    atr = latest.get("atr_14", entry * 0.005)
    if pd.isna(atr) or atr <= 0:
        atr = entry * 0.005

    if direction == "LONG":
        sl, tp = entry - atr * 2.0, entry + atr * 3.0
    else:
        sl, tp = entry + atr * 2.0, entry - atr * 3.0

    return TradeSignal(
        date, inst, direction, strength, entry, sl, tp,
        "FX_Carry_Momentum", regime,
        f"{regime}: {'; '.join(parts)}", atr,
    )


def generate_commodity_signal(inst: str, feat: pd.DataFrame, date) -> Optional[TradeSignal]:
    """Generate Commodities TS+Momentum signal for a single commodity on a given date."""
    mask = feat.index <= date
    f = feat[mask]
    if len(f) < 252:
        return None

    latest = f.iloc[-1]
    mom = latest.get("momentum_score", 0)
    trend = latest.get("trend_strength", 0)
    ts_slope = latest.get("ts_slope", None)
    regime = _get_regime(latest.get("vix", 20))

    if pd.isna(mom) or pd.isna(trend):
        return None

    direction = None
    strength = 0.0
    parts = []

    ts_dir = None
    if ts_slope is not None and not pd.isna(ts_slope):
        if ts_slope > 0.02:
            ts_dir = "LONG"
            parts.append(f"Backwardation={ts_slope:.3f}")
        elif ts_slope < -0.02:
            ts_dir = "SHORT"
            parts.append(f"Contango={ts_slope:.3f}")

    m_dir = None
    if abs(mom) > 0.8 and abs(trend) > 0.005:
        m_dir = "LONG" if (mom > 0 and trend > 0) else ("SHORT" if (mom < 0 and trend < 0) else None)
        if m_dir:
            parts.append(f"Mom={mom:.2f}")

    if ts_dir and m_dir and ts_dir == m_dir:
        direction, strength = ts_dir, 0.8
    elif ts_dir and m_dir:
        return None  # Conflicting — skip
    elif ts_dir:
        direction, strength = ts_dir, 0.5
    elif m_dir:
        direction, strength = m_dir, 0.5

    if direction is None or strength < 0.2:
        return None
    if regime == "HIGH_VOL":
        strength *= 0.6

    entry = latest["PX_LAST"]
    atr = latest.get("atr_14", entry * 0.01)
    if pd.isna(atr) or atr <= 0:
        atr = entry * 0.01

    if direction == "LONG":
        sl, tp = entry - atr * 2.5, entry + atr * 3.5
    else:
        sl, tp = entry + atr * 2.5, entry - atr * 3.5

    return TradeSignal(
        date, inst, direction, strength, entry, sl, tp,
        "Commodity_TS_Momentum", regime,
        f"{regime}: {'; '.join(parts)}", atr,
    )


# =============================================================================
# Backtest Engine
# =============================================================================

class BacktestEngine:
    """Core backtest execution engine."""

    def __init__(self, config: BacktestConfig):
        self.cfg = config
        self.capital = config.initial_capital
        self.peak_capital = config.initial_capital
        self.trades: List[Trade] = []
        self.open_trades: List[Trade] = []
        self.equity_curve = []
        self.daily_returns = []
        self.signals_generated: List[TradeSignal] = []
        self.signals_rejected = 0
        self.signals_killed = 0

        # Risk overlay
        self.risk_overlay = None
        if config.use_risk_overlay:
            try:
                from src.strategies.cross_asset_risk import CrossAssetRiskOverlay
                self.risk_overlay = CrossAssetRiskOverlay(
                    vix_kill_threshold=config.vix_kill_threshold
                )
            except ImportError:
                logger.warning("CrossAssetRiskOverlay not found, running without risk overlay")

    def _gross_exposure(self):
        return sum(t.position_size for t in self.open_trades)

    def _has_position(self, inst):
        return any(t.signal.instrument == inst for t in self.open_trades)

    def _calc_cost(self, notional, strategy):
        if strategy.startswith("FX"):
            bps = self.cfg.fx_spread_bps + self.cfg.fx_slippage_bps
        else:
            bps = self.cfg.cmdty_spread_bps + self.cfg.cmdty_slippage_bps
        return notional * bps / 10000 * 2  # Round-trip

    def _calc_position(self, entry, stop_loss):
        risk_amt = self.capital * self.cfg.risk_per_trade_pct
        risk_per_unit = abs(entry - stop_loss)
        if risk_per_unit <= 0:
            return 0, 0
        units = risk_amt / risk_per_unit
        notional = units * entry
        max_n = self.capital * self.cfg.max_position_pct
        if notional > max_n:
            notional = max_n
            units = notional / entry
            risk_amt = units * risk_per_unit
        return notional, risk_amt

    def _check_exit(self, trade: Trade, price, date):
        sig = trade.signal
        days = (date - trade.entry_date).days
        if sig.direction == "LONG":
            if price <= sig.stop_loss: return "STOP_LOSS"
            if price >= sig.take_profit: return "TAKE_PROFIT"
        else:
            if price >= sig.stop_loss: return "STOP_LOSS"
            if price <= sig.take_profit: return "TAKE_PROFIT"
        if days >= self.cfg.max_holding_days:
            return "MAX_HOLD"
        return None

    def _close_trade(self, trade: Trade, price, date, reason):
        sig = trade.signal
        trade.exit_date = date
        trade.exit_price = price
        trade.exit_reason = reason
        trade.holding_days = (date - trade.entry_date).days
        if sig.direction == "LONG":
            trade.gross_pnl = (price - trade.entry_price) / trade.entry_price * trade.position_size
        else:
            trade.gross_pnl = (trade.entry_price - price) / trade.entry_price * trade.position_size
        trade.cost = self._calc_cost(trade.position_size, sig.strategy)
        trade.net_pnl = trade.gross_pnl - trade.cost
        trade.pnl_pct = trade.net_pnl / trade.position_size * 100
        self.capital += trade.net_pnl
        self.peak_capital = max(self.peak_capital, self.capital)

    def run(self, features: Dict[str, pd.DataFrame], macros: pd.DataFrame) -> Dict[str, Any]:
        """Execute backtest over the configured date range."""
        overlay_label = "WITH" if self.risk_overlay else "WITHOUT"
        logger.info(f"Running backtest {overlay_label} risk overlay")

        start = pd.Timestamp(self.cfg.start_date)
        end = pd.Timestamp(self.cfg.end_date)

        all_dates = sorted(set().union(*(
            set(f.index[(f.index >= start) & (f.index <= end)]) for f in features.values()
        )))
        if not all_dates:
            return {"error": "No trading dates in range"}

        logger.info(f"  Period: {all_dates[0].date()} → {all_dates[-1].date()} ({len(all_dates)} days)")

        fx_inst = [k for k in features if k in ["EURUSD", "USDJPY", "GBPUSD", "AUDUSD"]]
        cmdty_inst = [k for k in features if k in ["WTI", "GOLD", "COPPER"]]

        prev_cap = self.capital
        last_sig_date = None
        daily_start = self.capital

        for i, date in enumerate(all_dates):
            if i == 0 or all_dates[i].date() != all_dates[i - 1].date():
                daily_start = self.capital

            # --- Risk Overlay ---
            risk_result = None
            if self.risk_overlay:
                vix_hist = macros["VIX"][macros.index <= date].tail(300)
                vix_val = vix_hist.iloc[-1] if len(vix_hist) > 0 else np.nan
                dxy_hist = macros["DXY"][macros.index <= date].tail(300) if "DXY" in macros.columns else None
                spx_hist = macros["SPX"][macros.index <= date].tail(300) if "SPX" in macros.columns else None
                y10_hist = macros["US_10Y_YIELD"][macros.index <= date].tail(300) if "US_10Y_YIELD" in macros.columns else None

                risk_result = self.risk_overlay.compute_risk_score(
                    vix=vix_val, vix_history=vix_hist,
                    dxy_history=dxy_hist, spx_history=spx_hist,
                    us10y_history=y10_hist, as_of_date=date,
                )

                # Circuit breaker
                cb = self.risk_overlay.check_circuit_breaker(self.capital, self.peak_capital, daily_start)
                if cb.halt:
                    for trade in self.open_trades:
                        inst = trade.signal.instrument
                        if inst in features and date in features[inst].index:
                            self._close_trade(trade, features[inst].loc[date, "PX_LAST"], date, "CIRCUIT_BREAKER")
                            self.trades.append(trade)
                    self.open_trades = []

            # --- Check Open Trades ---
            still_open = []
            for trade in self.open_trades:
                inst = trade.signal.instrument
                if inst in features and date in features[inst].index:
                    px = features[inst].loc[date, "PX_LAST"]
                    reason = self._check_exit(trade, px, date)
                    if reason:
                        self._close_trade(trade, px, date, reason)
                        self.trades.append(trade)
                    else:
                        still_open.append(trade)
                else:
                    still_open.append(trade)
            self.open_trades = still_open

            # --- Generate New Signals ---
            should_signal = last_sig_date is None or (date - last_sig_date).days >= self.cfg.signal_rebalance_days
            if should_signal:
                last_sig_date = date

                allow_new = True
                position_scalar = 1.0
                if risk_result:
                    if risk_result.regime == "KILL" or self.risk_overlay.circuit_breaker_active:
                        allow_new = False
                        self.signals_killed += 1
                    else:
                        position_scalar = risk_result.position_scalar

                if allow_new:
                    for inst in fx_inst:
                        if self._has_position(inst) or len(self.open_trades) >= self.cfg.max_concurrent:
                            continue
                        signal = generate_fx_signal(inst, features[inst], date)
                        if signal:
                            self.signals_generated.append(signal)
                            if self._gross_exposure() / self.capital >= self.cfg.max_gross_exposure:
                                self.signals_rejected += 1
                                continue
                            notional, risk = self._calc_position(signal.entry_price, signal.stop_loss)
                            notional *= position_scalar
                            risk *= position_scalar
                            signal.risk_overlay_scalar = position_scalar
                            if notional > 0:
                                self.open_trades.append(Trade(signal, date, signal.entry_price, notional, risk))

                    for inst in cmdty_inst:
                        if self._has_position(inst) or len(self.open_trades) >= self.cfg.max_concurrent:
                            continue
                        signal = generate_commodity_signal(inst, features[inst], date)
                        if signal:
                            self.signals_generated.append(signal)
                            if self._gross_exposure() / self.capital >= self.cfg.max_gross_exposure:
                                self.signals_rejected += 1
                                continue
                            notional, risk = self._calc_position(signal.entry_price, signal.stop_loss)
                            notional *= position_scalar
                            risk *= position_scalar
                            signal.risk_overlay_scalar = position_scalar
                            if notional > 0:
                                self.open_trades.append(Trade(signal, date, signal.entry_price, notional, risk))

            # --- Mark-to-Market ---
            mtm = self.capital
            for trade in self.open_trades:
                inst = trade.signal.instrument
                if inst in features and date in features[inst].index:
                    px = features[inst].loc[date, "PX_LAST"]
                    if trade.signal.direction == "LONG":
                        mtm += (px - trade.entry_price) / trade.entry_price * trade.position_size
                    else:
                        mtm += (trade.entry_price - px) / trade.entry_price * trade.position_size

            self.equity_curve.append((date, mtm))
            dr = (mtm - prev_cap) / prev_cap if prev_cap > 0 else 0
            self.daily_returns.append((date, dr))
            prev_cap = mtm

            if (i + 1) % 250 == 0:
                regime_str = risk_result.regime if risk_result else "N/A"
                logger.info(
                    f"  Day {i + 1}/{len(all_dates)}: ${mtm:,.0f} | "
                    f"Open={len(self.open_trades)} | Closed={len(self.trades)} | "
                    f"Regime={regime_str}"
                )

        # Close remaining positions
        for trade in self.open_trades:
            inst = trade.signal.instrument
            if inst in features:
                self._close_trade(trade, features[inst]["PX_LAST"].iloc[-1], all_dates[-1], "END_OF_BACKTEST")
                self.trades.append(trade)
        self.open_trades = []

        return self._compute_results()

    def _compute_results(self) -> Dict[str, Any]:
        """Compute comprehensive backtest metrics."""
        if not self.trades:
            return {"error": "No trades executed"}

        winners = [t for t in self.trades if t.is_winner]
        losers = [t for t in self.trades if not t.is_winner]

        eq = pd.Series(dict(self.equity_curve))
        rets = pd.Series(dict(self.daily_returns))

        running_max = eq.cummax()
        dd = (eq - running_max) / running_max

        n_years = (eq.index[-1] - eq.index[0]).days / 365.25
        total_ret = eq.iloc[-1] / self.cfg.initial_capital - 1
        cagr = (eq.iloc[-1] / self.cfg.initial_capital) ** (1 / max(n_years, 0.01)) - 1

        clean_rets = rets.replace([np.inf, -np.inf], np.nan).dropna()
        ann_vol = clean_rets.std() * np.sqrt(252)
        ann_ret = clean_rets.mean() * 252
        sharpe = ann_ret / ann_vol if ann_vol > 0 else 0

        down_rets = clean_rets[clean_rets < 0]
        down_vol = down_rets.std() * np.sqrt(252) if len(down_rets) > 0 else 0
        sortino = ann_ret / down_vol if down_vol > 0 else 0

        gross_profit = sum(t.net_pnl for t in winners)
        gross_loss = abs(sum(t.net_pnl for t in losers)) if losers else 1
        pf = gross_profit / gross_loss if gross_loss > 0 else float("inf")

        def _max_consec(lst, val):
            mx, cur = 0, 0
            for v in lst:
                if v == val:
                    cur += 1
                    mx = max(mx, cur)
                else:
                    cur = 0
            return mx

        results_list = [1 if t.is_winner else 0 for t in self.trades]

        def _breakdown(trade_list):
            w = [t for t in trade_list if t.is_winner]
            l = [t for t in trade_list if not t.is_winner]
            return {
                "trades": len(trade_list),
                "win_rate": len(w) / len(trade_list) if trade_list else 0,
                "total_pnl": sum(t.net_pnl for t in trade_list),
                "avg_pnl_pct": np.mean([t.pnl_pct for t in trade_list]) if trade_list else 0,
                "profit_factor": (
                    sum(t.net_pnl for t in w) / max(abs(sum(t.net_pnl for t in l)), 1)
                    if trade_list else 0
                ),
            }

        return {
            "summary": {
                "total_return_pct": total_ret * 100,
                "cagr_pct": cagr * 100,
                "annualized_vol_pct": ann_vol * 100,
                "sharpe_ratio": sharpe,
                "sortino_ratio": sortino,
                "max_drawdown_pct": dd.min() * 100,
                "profit_factor": pf,
                "total_pnl": sum(t.net_pnl for t in self.trades),
                "total_costs": sum(t.cost for t in self.trades),
                "final_capital": self.capital,
            },
            "trade_stats": {
                "total_trades": len(self.trades),
                "winners": len(winners),
                "losers": len(losers),
                "win_rate_pct": len(winners) / len(self.trades) * 100,
                "avg_win_pct": np.mean([t.pnl_pct for t in winners]) if winners else 0,
                "avg_loss_pct": np.mean([t.pnl_pct for t in losers]) if losers else 0,
                "avg_holding_days": np.mean([t.holding_days for t in self.trades]),
                "max_consec_wins": _max_consec(results_list, 1),
                "max_consec_losses": _max_consec(results_list, 0),
                "signals_generated": len(self.signals_generated),
                "signals_rejected": self.signals_rejected,
                "signals_killed_by_overlay": self.signals_killed,
            },
            "by_strategy": {
                s: _breakdown([t for t in self.trades if t.signal.strategy == s])
                for s in set(t.signal.strategy for t in self.trades)
            },
            "by_instrument": {
                s: _breakdown([t for t in self.trades if t.signal.instrument == s])
                for s in sorted(set(t.signal.instrument for t in self.trades))
            },
            "by_regime": {
                s: _breakdown([t for t in self.trades if t.signal.regime == s])
                for s in set(t.signal.regime for t in self.trades)
            },
            "by_exit_reason": {
                r: {
                    "count": len([t for t in self.trades if t.exit_reason == r]),
                    "avg_pnl_pct": np.mean([t.pnl_pct for t in self.trades if t.exit_reason == r]),
                    "total_pnl": sum(t.net_pnl for t in self.trades if t.exit_reason == r),
                }
                for r in set(t.exit_reason for t in self.trades if t.exit_reason)
            },
            "equity_curve": eq,
            "drawdown": dd,
            "daily_returns": rets,
        }


# =============================================================================
# CLI Entry Point
# =============================================================================

def main():
    parser = argparse.ArgumentParser(description="Run historical backtest")
    parser.add_argument("--start", default="2021-01-01", help="Start date (YYYY-MM-DD)")
    parser.add_argument("--end", default="2026-02-01", help="End date (YYYY-MM-DD)")
    parser.add_argument("--capital", type=float, default=100_000, help="Initial capital")
    parser.add_argument("--no-risk-overlay", action="store_true", help="Disable risk overlay")
    parser.add_argument("--vix-kill", type=float, default=30.0, help="VIX kill switch level")
    parser.add_argument("--output", default=None, help="Output Excel path")
    parser.add_argument("--data-dir", default=None, help="Data directory path")
    args = parser.parse_args()

    cfg = BacktestConfig(
        start_date=args.start,
        end_date=args.end,
        initial_capital=args.capital,
        use_risk_overlay=not args.no_risk_overlay,
        vix_kill_threshold=args.vix_kill,
    )
    if args.data_dir:
        cfg.data_dir = Path(args.data_dir)
    else:
        cfg.data_dir = find_data_dir()

    data = load_all_data(cfg.data_dir)
    features = compute_all_features(data)
    macros = data["macros"]

    engine = BacktestEngine(cfg)
    results = engine.run(features, macros)

    if "error" in results:
        logger.error(results["error"])
        return

    # Print summary
    s = results["summary"]
    t = results["trade_stats"]
    print(f"\n{'='*50}")
    print(f"  BACKTEST RESULTS")
    print(f"{'='*50}")
    print(f"  Total Return:  {s['total_return_pct']:+.2f}%")
    print(f"  Sharpe Ratio:  {s['sharpe_ratio']:.2f}")
    print(f"  Max Drawdown:  {s['max_drawdown_pct']:.2f}%")
    print(f"  Profit Factor: {s['profit_factor']:.2f}")
    print(f"  Total Trades:  {t['total_trades']}")
    print(f"  Win Rate:      {t['win_rate_pct']:.1f}%")
    print(f"  Final Capital: ${s['final_capital']:,.0f}")
    print(f"{'='*50}")

    # Save JSON
    output_dir = Path(args.output).parent if args.output else cfg.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    json_path = output_dir / "backtest_results.json"
    with open(json_path, "w") as f:
        json.dump({
            "summary": results["summary"],
            "trade_stats": results["trade_stats"],
            "by_strategy": results["by_strategy"],
            "by_instrument": results["by_instrument"],
        }, f, indent=2, default=str)
    logger.info(f"Results saved: {json_path}")


if __name__ == "__main__":
    main()
